{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constrActive optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style><style>.output_png {display: table-cell;text-align: center;vertical-align: middle;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "configure_logging(logging.getLogger(),verbosity=1)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML('<style>.container { width:95% !important; }</style><style>.output_png {display: table-cell;text-align: center;vertical-align: middle;}</style>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up input graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from toolz import curry, pipe\n",
    "from eden_chem.io.pubchem import download\n",
    "from eden_chem.obabel import load as babel_load\n",
    "\n",
    "download_active = curry(download)(active=True)\n",
    "download_inactive = curry(download)(active=False)\n",
    "\n",
    "def get_pos_graphs(assay_id): return pipe(assay_id, download_active, babel_load, list)\n",
    "def get_neg_graphs(assay_id): return pipe(assay_id, download_inactive, babel_load, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from eden.graph import Vectorizer\n",
    "import random\n",
    "from constrActive import min_similarity_selection\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def outliers(graphs, k=3):\n",
    "    vec = Vectorizer(r=3, d=3, normalization=False, inner_normalization=False, n_jobs=1)\n",
    "    x = vec.transform(graphs)\n",
    "    knn = NearestNeighbors()\n",
    "    knn.fit(x)\n",
    "    neigbhbors = knn.kneighbors(x, n_neighbors=k, return_distance=False)\n",
    "    outlier_list = []\n",
    "    non_outlier_list = []\n",
    "    for i,ns in enumerate(neigbhbors):\n",
    "        not_outlier = False\n",
    "        for n in ns[1:]:\n",
    "            if i in list(neigbhbors[n,:]):\n",
    "                not_outlier=True\n",
    "                break\n",
    "        if not_outlier is False:\n",
    "            outlier_list.append(i)\n",
    "        else:\n",
    "            non_outlier_list.append(i)\n",
    "    return outlier_list, non_outlier_list\n",
    "\n",
    "def select_non_outliers(graphs, k=3):\n",
    "    outlier_list, non_outlier_list = outliers(graphs, k)\n",
    "    graphs = [graphs[i] for i in non_outlier_list]\n",
    "    logging.info('outlier removal:%d'%len(graphs))\n",
    "    return graphs\n",
    "\n",
    "def remove_similar_pairs(graphs):\n",
    "    vec = Vectorizer(r=3, d=3, normalization=False, inner_normalization=False, n_jobs=1)\n",
    "    x = vec.transform(graphs)\n",
    "    matrix = cosine_similarity(x)\n",
    "    scores = np.array([1]*len(graphs))\n",
    "    ids = min_similarity_selection(matrix, scores=scores, max_num=len(graphs)/2)\n",
    "    graphs = [graphs[i] for i in ids]\n",
    "    logging.info('simila pairs removal:%d'%len(graphs))\n",
    "    return graphs\n",
    "    \n",
    "def trim_by_size(graphs, fraction_to_remove=.1):\n",
    "    frac = 1.0 - fraction_to_remove/2\n",
    "    size = len(graphs)\n",
    "    graphs = sorted(graphs, key=lambda g:len(g))[:int(size*frac)]\n",
    "    graphs = sorted(graphs, key=lambda g:len(g), reverse=True)[:int(size*frac)]\n",
    "    logging.info('trimming by size:%d'%len(graphs))\n",
    "    return graphs\n",
    "\n",
    "def trim_by_num(graphs, max_size):\n",
    "    if len(graphs) > max_size:\n",
    "        graphs = random.sample(graphs, max_size)\n",
    "    logging.info('trimming by num:%d'%len(graphs))\n",
    "    return graphs\n",
    "    \n",
    "def pre_process(graphs, fraction_to_remove=.1, n_neighbors_for_outliers=3, max_size=500):\n",
    "    logging.info('original size:%d'% len(graphs))\n",
    "    graphs = trim_by_size(graphs, fraction_to_remove)\n",
    "    graphs = select_non_outliers(graphs, k=n_neighbors_for_outliers)\n",
    "    graphs = remove_similar_pairs(graphs)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def setup(graphs=None, k=None, m=None, vectorizer=None):\n",
    "    x = vectorizer.transform(graphs)\n",
    "    knn = NearestNeighbors()\n",
    "    knn.fit(x)\n",
    "    neigbhbors = knn.kneighbors(x, n_neighbors=k+m+1+1+1, return_distance=False)\n",
    "    return neigbhbors\n",
    "\n",
    "def select(id, neigbhbors, graphs, vectorizer, k=None, m=None):\n",
    "    sel_neigbhbors = neigbhbors[id][1:]\n",
    "    reference_graph = graphs[id]\n",
    "    reference_vec = vectorizer.transform([reference_graph])[0]\n",
    "    reference_graphs = [graphs[i] for i in sel_neigbhbors[:k]]\n",
    "    reference_vecs = vectorizer.transform(reference_graphs)\n",
    "    distances = euclidean_distances(reference_vec, reference_vecs)[0]\n",
    "    pos_graphs = [graphs[i] for i in sel_neigbhbors[k:k+m/2]]\n",
    "    neg_graphs = [graphs[i] for i in sel_neigbhbors[k+m/2:k+m]]\n",
    "    seed_graph = graphs[sel_neigbhbors[k+m+1]]\n",
    "    return reference_graph, seed_graph, reference_graphs, distances, pos_graphs, neg_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pareto_graph_optimizer import MultiObjectiveCostEstimator\n",
    "from pareto_graph_optimizer import optimize_desired_distances\n",
    "import time\n",
    "\n",
    "def estimate_reconstruction_distance(id, neigbhbors, all_graphs, grammar, vectorizer, k=5, m=100):\n",
    "    ts = time.time()\n",
    "    res = select(id, neigbhbors, all_graphs, vectorizer, k=k, m=m)\n",
    "    reference_graph, start_graph, reference_graphs, desired_distances, loc_pos_graphs, loc_neg_graphs = res\n",
    "\n",
    "    cost_estimator = MultiObjectiveCostEstimator(vectorizer, improve=True).fit(loc_pos_graphs, loc_neg_graphs)\n",
    "\n",
    "    res = optimize_desired_distances(start_graph, desired_distances, reference_graphs, vectorizer, grammar, cost_estimator)\n",
    "    reference_graphs, pareto_set_graphs = res\n",
    "\n",
    "    reference_vec = vectorizer.transform([reference_graph])[0]\n",
    "    pareto_set_vecs = vectorizer.transform(pareto_set_graphs)\n",
    "    distances = euclidean_distances(reference_vec, pareto_set_vecs)[0]\n",
    "    min_dist = min(distances)/min(desired_distances)\n",
    "    te = time.time()\n",
    "    return (min_dist, id, te-ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pareto_graph_optimizer import GrammarWrapper\n",
    "\n",
    "def make_grammars(min_counts, vectorizer):\n",
    "    grammars=dict()\n",
    "    for min_count in min_counts:\n",
    "        grammar = GrammarWrapper(vectorizer,radius_list=[0,1,2,3],thickness_list=[2],\n",
    "                                 min_cip_count=min_count,min_interface_count=min_count)\n",
    "        grammar.fit(all_graphs)\n",
    "        grammars[min_count] = grammar\n",
    "        logging.info('min count threshold: %d   grammar: %s' % (min_count, grammar))\n",
    "    return grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from eden import apply_async\n",
    "\n",
    "def reconstruction_error_experiment(dim, all_graphs, k=5, m=20, grammar=None, vectorizer=None):\n",
    "    neigbhbors = setup(graphs=all_graphs, k=k, m=m, vectorizer=vectorizer)\n",
    "\n",
    "    pool = multiprocessing.Pool()\n",
    "    res = [apply_async(\n",
    "        pool, estimate_reconstruction_distance, args=(id, neigbhbors, all_graphs, grammar, vectorizer, k, m))\n",
    "           for id in range(dim)]\n",
    "    min_dists=[]\n",
    "    for p in res:\n",
    "        min_dist,id,dt = p.get()\n",
    "        min_dists.append(min_dist)\n",
    "        logging.debug('id:%3d min distance:%.2f  (%.2f sec)'%(id, min_dist, dt))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return min_dists\n",
    "\n",
    "def display_results(min_dists, info_tuple):\n",
    "    k, m, duration = info_tuple\n",
    "    logging.info('Runtime: %.2f sec' % duration)\n",
    "    logging.info('k:%d  m:%d' % (k,m))\n",
    "    dim = len(min_dists)\n",
    "    logging.info('Avg: %.2f'% np.mean(min_dists))\n",
    "    zc = sum(1 for d in min_dists if d==0)\n",
    "    logging.info('Perfect reconstruction in %d cases over %d (%.2f)'%(zc,dim, float(zc)/dim))\n",
    "    bc = sum(1 for d in min_dists if d<1)\n",
    "    logging.info('Better than 1-NN reconstruction in %d cases over %d (%.2f)'%(bc,dim, float(bc)/dim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assay_id = '651610' #apr93 23k mols\n",
    "assay_id = '1834'   #apr90 500 mols\n",
    "assay_id = '624466' #apr88 p5k n23k\n",
    "assay_id = '588350' #apr86 p1k n600\n",
    "assay_id = '449764' #apr85\n",
    "assay_id = '492952' #apr85\n",
    "assay_id = '463112' #apr82\n",
    "assay_id = '463213' #apr70\n",
    "assay_id = '119'    #apr60 30k mols\n",
    "assay_id = '1224857'#apr10\n",
    "assay_id = '2326'   #apr03 200k mols\n",
    "\n",
    "#-------------------------------------------------\n",
    "# choose\n",
    "assay_id = '624466' #apr88 p5k n23k\n",
    "assay_id = '588350' #apr86 p1k n600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove outliers, remove paiwise too similar, cluster in 2 and split in train and test\n",
    "# induce grammar only on train\n",
    "# reconstruct test instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive graphs\n",
      "original size:1232\n",
      "trimming by size:1170\n",
      "outlier removal:649\n",
      "simila pairs removal:324\n",
      "Negative graphs\n",
      "original size:634\n",
      "trimming by size:602\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-037e5d9297e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"# extract pos and neg graphs\\npos_graphs, neg_graphs = get_pos_graphs(assay_id), get_neg_graphs(assay_id)\\n\\n# remove too large and too small graphs and outliers\\nargs=dict(fraction_to_remove=.1, n_neighbors_for_outliers=3, max_size=300)\\nlogging.info('Positive graphs')\\npos_graphs = pre_process(pos_graphs, **args)\\nlogging.info('Negative graphs')\\nneg_graphs = pre_process(neg_graphs, **args)\\nall_graphs = pos_graphs+neg_graphs\\n\\n# setup colors\\nfrom eden.display import map_labels_to_colors\\nlabel_colors = map_labels_to_colors(pos_graphs + neg_graphs)\\nfrom graphlearn.utils import draw\\ndraw_params = dict(n_graphs_per_line=7, size=9, colormap='Paired', vertex_color='_labels_', vertex_color_dict=label_colors, vertex_alpha=0.5, edge_alpha=0.2)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/fc334/miniconda2/envs/eden_env/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/fc334/miniconda2/envs/eden_env/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fc334/miniconda2/envs/eden_env/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b02c5d5d9ec4>\u001b[0m in \u001b[0;36mpre_process\u001b[0;34m(graphs, fraction_to_remove, n_neighbors_for_outliers, max_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original size:%d'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrim_by_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction_to_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_non_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neighbors_for_outliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_similar_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b02c5d5d9ec4>\u001b[0m in \u001b[0;36mselect_non_outliers\u001b[0;34m(graphs, k)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_non_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0moutlier_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_outlier_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_outlier_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outlier removal:%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b02c5d5d9ec4>\u001b[0m in \u001b[0;36moutliers\u001b[0;34m(graphs, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moutliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fc334/Sync/Projects/EDeN/eden_world/eden_git/eden/graph.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, graphs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \"\"\"\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_serial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fc334/Sync/Projects/EDeN/eden_world/eden_git/eden/graph.pyc\u001b[0m in \u001b[0;36m_transform_serial\u001b[0;34m(self, graphs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             raise Exception('ERROR: something went wrong:\\\n\u001b[1;32m    318\u001b[0m                 no graphs are present in current iterator.')\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_dict_to_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fc334/Sync/Projects/EDeN/eden_world/eden_git/eden/graph.pyc\u001b[0m in \u001b[0;36m_convert_dict_to_sparse_matrix\u001b[0;34m(self, feature_rows)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_row\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# extract pos and neg graphs\n",
    "pos_graphs, neg_graphs = get_pos_graphs(assay_id), get_neg_graphs(assay_id)\n",
    "\n",
    "# remove too large and too small graphs and outliers\n",
    "args=dict(fraction_to_remove=.1, n_neighbors_for_outliers=3, max_size=300)\n",
    "logging.info('Positive graphs')\n",
    "pos_graphs = pre_process(pos_graphs, **args)\n",
    "logging.info('Negative graphs')\n",
    "neg_graphs = pre_process(neg_graphs, **args)\n",
    "all_graphs = pos_graphs+neg_graphs\n",
    "\n",
    "# setup colors\n",
    "from eden.display import map_labels_to_colors\n",
    "label_colors = map_labels_to_colors(pos_graphs + neg_graphs)\n",
    "from graphlearn.utils import draw\n",
    "draw_params = dict(n_graphs_per_line=7, size=9, colormap='Paired', vertex_color='_labels_', vertex_color_dict=label_colors, vertex_alpha=0.5, edge_alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from eden.graph import Vectorizer\n",
    "vectorizer = Vectorizer(r=3, d=3,normalization=False,inner_normalization=False,n_jobs=1)\n",
    "\n",
    "min_counts=range(3,0,-1)\n",
    "grammars = make_grammars(min_counts, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_test_instances=50\n",
    "k=5\n",
    "\n",
    "for min_count in sorted(grammars, reverse=True):\n",
    "    for m in [20,80,160]:\n",
    "        logging.info('-'*130)\n",
    "        grammar = grammars[min_count]\n",
    "        logging.info('grammar: min_count: %d    %s' % (min_count, grammar))\n",
    "        ts = time.time()\n",
    "        min_dists = reconstruction_error_experiment(num_test_instances, all_graphs, k, m, grammar, vectorizer)\n",
    "        te = time.time()\n",
    "        duration = te-ts\n",
    "        info_tuple = (k, m, duration)\n",
    "        display_results(min_dists, info_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "### Grammar\n",
    " #instances: 432   #interfaces: 10660   #cores: 5588   #core-interface-pairs: 16311\n",
    "\n",
    "CPU times: user 13.6 s, sys: 972 ms, total: 14.6 s\n",
    "\n",
    "Wall time: 19.2 s\n",
    "\n",
    "\n",
    "### Results\n",
    "avg: 0.13\n",
    "\n",
    "Perfect reconstruction in 87 cases over 100 (0.87)\n",
    "\n",
    "Better than 1-NN reconstruction in 91 cases over 100 (0.91)\n",
    "\n",
    "CPU times: user 2h 14min 56s, sys: 6min 42s, total: 2h 21min 38s\n",
    "\n",
    "Wall time: 2h 32min 41s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
